{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, listdir\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from os import listdir, path, stat\n",
    "import logging\n",
    "from xbrl.cache import HttpCache\n",
    "from xbrl.instance import XbrlParser\n",
    "import json\n",
    "import uuid\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from digiaccounts.digiaccounts_data import (\n",
    "    get_financial_table,\n",
    "    get_startend_period,\n",
    "    get_company_address,\n",
    "    get_company_registration,\n",
    "    get_accounting_software,\n",
    "    get_share_info,\n",
    "    get_director_names,\n",
    "    get_company_postcode,\n",
    "    get_average_employees,\n",
    "    get_dormant_state\n",
    ")\n",
    "\n",
    "from digiaccounts.digiaccounts_io import (\n",
    "    get_account_information_dictionary,\n",
    "    add_account_to_collection,\n",
    "    create_unique_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database(dbname):\n",
    "\n",
    "    CONNECTION_STRING = 'mongodb://localhost:27017'\n",
    "\n",
    "    client = MongoClient(CONNECTION_STRING)\n",
    "\n",
    "    return client[dbname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb = get_database('annual_accounts_db')\n",
    "filed_accounts = mongodb['filed_accounts']\n",
    "index_accounts = mongodb['index_accounts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = filed_accounts.distinct('registration_number')\n",
    "# len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = filed_accounts.aggregate(\n",
    "#     [ \n",
    "#         {   \n",
    "#             \"$group\":  { \n",
    "#                     \"_id\": \"$registration_number\", \n",
    "#                     \"count\": { \"$sum\": 1 } \n",
    "#                 } \n",
    "#         },\n",
    "#         {\n",
    "#             \"$group\": {\n",
    "#                 \"_id\": None, \n",
    "#                 \"maxCount\": { \"$max\": \"$count\" },\n",
    "#                 \"minCount\": { \"$min\": \"$count\" },\n",
    "#                 \"avgCount\": { \"$avg\": \"$count\" }\n",
    "#             }\n",
    "#         }\n",
    "#     ]    \n",
    "# )\n",
    "# for d in documents:\n",
    "#     print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = filed_accounts.aggregate(\n",
    "#     [\n",
    "#         {\n",
    "#             \"$match\": {\n",
    "#                 \"$and\": [\n",
    "#                     {\"$expr\": {\"$lt\": [{\"$dateFromString\": {\"dateString\": \"$period_ending\"}}, datetime.strptime('20180331', \"%Y%m%d\")]}},\n",
    "#                     {\"is_dormant\": {'$eq':False}},\n",
    "#                     {\"$expr\": {\"$gt\": [{\"$toDouble\": \"$average_employees\"}, 0]}}\n",
    "#                 ]\n",
    "#             }\n",
    "#         },\n",
    "#         {\n",
    "#            \"$group\": {\n",
    "#                 \"_id\": 'Ending 2018', \n",
    "#                 \"entityCount\": {\"$sum\": 1},\n",
    "#                 \"maxEmployees\": { \"$max\": {\"$toDouble\": \"$average_employees\" } },\n",
    "#                 \"minEmployees\": { \"$min\": {\"$toDouble\": \"$average_employees\" } },\n",
    "#                 \"avgEmployees\": { \"$avg\": {\"$toDouble\": \"$average_employees\" } }\n",
    "#             } \n",
    "#         }\n",
    "#     ]\n",
    "# )\n",
    "# for d in documents:\n",
    "#     print(d)\n",
    "\n",
    "# documents = filed_accounts.aggregate(\n",
    "#     [\n",
    "#         {\n",
    "#             \"$match\": {\n",
    "#                 \"$and\": [\n",
    "#                     {\"$expr\": {\"$gte\": [{\"$dateFromString\": {\"dateString\": \"$period_ending\"}}, datetime.strptime('20180331', \"%Y%m%d\")]}},\n",
    "#                     {\"$expr\": {\"$lt\": [{\"$dateFromString\": {\"dateString\": \"$period_ending\"}}, datetime.strptime('20190331', \"%Y%m%d\")]}},\n",
    "#                     {\"is_dormant\": {'$eq':False}},\n",
    "#                     {\"$expr\": {\"$gt\": [{\"$toDouble\": \"$average_employees\"}, 0]}}\n",
    "#                 ]\n",
    "                \n",
    "#             }\n",
    "#         },\n",
    "#         {\n",
    "#            \"$group\": {\n",
    "#                 \"_id\": 'Ending 2019', \n",
    "#                 \"entityCount\": {\"$sum\": 1},\n",
    "#                 \"maxEmployees\": { \"$max\": {\"$toDouble\": \"$average_employees\" } },\n",
    "#                 \"minEmployees\": { \"$min\": {\"$toDouble\": \"$average_employees\" } },\n",
    "#                 \"avgEmployees\": { \"$avg\": {\"$toDouble\": \"$average_employees\" } }\n",
    "#             } \n",
    "#         }\n",
    "#     ]\n",
    "# )\n",
    "# for d in documents:\n",
    "#     print(d)\n",
    "\n",
    "# documents = filed_accounts.aggregate(\n",
    "#     [\n",
    "#         {\n",
    "#             \"$match\": {\n",
    "#                     \"$and\": [\n",
    "#                     {\"$expr\": {\"$gte\": [{\"$dateFromString\": {\"dateString\": \"$period_ending\"}}, datetime.strptime('20190331', \"%Y%m%d\")]}},\n",
    "#                     {\"$expr\": {\"$lt\": [{\"$dateFromString\": {\"dateString\": \"$period_ending\"}}, datetime.strptime('20200331', \"%Y%m%d\")]}},\n",
    "#                     {\"is_dormant\": {'$eq':False}},\n",
    "#                     {\"$expr\": {\"$gt\": [{\"$toDouble\": \"$average_employees\"}, 0]}}\n",
    "#                 ]\n",
    "#             }\n",
    "#         },\n",
    "#         {\n",
    "#            \"$group\": {\n",
    "#                 \"_id\": 'Ending 2020',\n",
    "#                 \"entityCount\": {\"$sum\": 1}, \n",
    "#                 \"maxEmployees\": { \"$max\": {\"$toDouble\": \"$average_employees\" } },\n",
    "#                 \"minEmployees\": { \"$min\": {\"$toDouble\": \"$average_employees\" } },\n",
    "#                 \"avgEmployees\": { \"$avg\": {\"$toDouble\": \"$average_employees\" } }\n",
    "#             } \n",
    "#         }\n",
    "#     ]\n",
    "# )\n",
    "# for d in documents:\n",
    "#     print(d)\n",
    "\n",
    "# documents = filed_accounts.aggregate(\n",
    "#     [\n",
    "#         {\n",
    "#             \"$match\": {\n",
    "#                 \"$and\": [\n",
    "#                     {\"$expr\": {\"$gte\": [{\"$dateFromString\": {\"dateString\": \"$period_ending\"}}, datetime.strptime('20200331', \"%Y%m%d\")]}},\n",
    "#                     {\"$expr\": {\"$lt\": [{\"$dateFromString\": {\"dateString\": \"$period_ending\"}}, datetime.strptime('20210331', \"%Y%m%d\")]}},\n",
    "#                     {\"is_dormant\": {'$eq':False}},\n",
    "#                     {\"$expr\": {\"$gte\": [{\"$toDouble\": \"$average_employees\"}, 1]}}\n",
    "#                 ]\n",
    "#             }\n",
    "#         },\n",
    "#         {\n",
    "#             \"$group\": {\n",
    "#                 \"_id\": 'Ending 2021',\n",
    "#                 \"entityCount\": {\"$sum\": 1},\n",
    "#                 \"maxEmployees\": {\"$max\": {\"$toDouble\": \"$average_employees\"}},\n",
    "#                 \"minEmployees\": {\"$min\": {\"$toDouble\": \"$average_employees\"}},\n",
    "#                 \"avgEmployees\": {\"$avg\": {\"$toDouble\": \"$average_employees\"}}\n",
    "#             }\n",
    "#         }\n",
    "#     ]\n",
    "# )\n",
    "# for d in documents:\n",
    "#     print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query1 = {'$and':[\n",
    "    \n",
    "#         {\"$expr\": {\n",
    "#             \"$lt\": [{ \"$dateFromString\": { \"dateString\": \"$period_ending\" }}, datetime.strptime('20180331', \"%Y%m%d\") ]\n",
    "#         }},\n",
    "#         {\"is_dormant\": {'$eq':True}}\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# query2 = {'$and':[\n",
    "    \n",
    "#         {\"$expr\": {\n",
    "#             \"$gte\": [{ \"$dateFromString\": { \"dateString\": \"$period_ending\" }}, datetime.strptime('20200331', \"%Y%m%d\") ]\n",
    "#         }},\n",
    "#         {\"is_dormant\": {'$eq':False}}\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# query_comb = {'$or': [\n",
    "#         query1,\n",
    "#         query2\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# documents = filed_accounts.aggregate(\n",
    "#     [\n",
    "#         {\n",
    "#             \"$match\": query_comb\n",
    "#         },\n",
    "#         {\n",
    "#             \"$group\": {\n",
    "#                 \"_id\": \"$registration_number\",\n",
    "#                 \"reg_filter_count\": {\"$sum\": 1} \n",
    "#             }\n",
    "#         },\n",
    "#         {\n",
    "#             \"$match\": {\n",
    "#                 \"$expr\": {\n",
    "#                     \"$gt\": [\"$reg_filter_count\", 1]\n",
    "#                 }\n",
    "#             }\n",
    "#         }\n",
    "#     ]\n",
    "# )\n",
    "# print('Started/Resumed Trading')\n",
    "# for d in documents:\n",
    "#     print(d['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query1 = {'$and':[\n",
    "    \n",
    "#         {\"$expr\": {\n",
    "#             \"$lt\": [{ \"$dateFromString\": { \"dateString\": \"$period_ending\" }}, datetime.strptime('20180331', \"%Y%m%d\") ]\n",
    "#         }},\n",
    "#         {\"is_dormant\": {'$eq':False}}\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# query2 = {'$and':[\n",
    "    \n",
    "#         {\"$expr\": {\n",
    "#             \"$gt\": [{ \"$dateFromString\": { \"dateString\": \"$period_ending\" }}, datetime.strptime('20200331', \"%Y%m%d\") ]\n",
    "#         }},\n",
    "#         {\"is_dormant\": {'$eq':True}}\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# query_comb = {'$or': [\n",
    "#         query1,\n",
    "#         query2\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# documents = filed_accounts.aggregate(\n",
    "#     [\n",
    "#         {\n",
    "#             \"$match\": query_comb\n",
    "#         },\n",
    "#         {\n",
    "#             \"$group\": {\n",
    "#                 \"_id\": \"$registration_number\",\n",
    "#                 \"reg_filter_count\": {\"$sum\": 1} \n",
    "#             }\n",
    "#         },\n",
    "#         {\n",
    "#             \"$match\": {\n",
    "#                 \"$expr\": {\n",
    "#                     \"$gt\": [\"$reg_filter_count\", 1]\n",
    "#                 }\n",
    "#             }\n",
    "#         }\n",
    "#     ]\n",
    "# )\n",
    "# print('Became Dormant')\n",
    "# for d in documents:\n",
    "#     print(d['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggrigation = filed_accounts.aggregate([\n",
    "#     {\"$match\": query_comb},\n",
    "#     {\"$group\": {\"_id\": \"$registration_number\", }}\n",
    "# ])\n",
    "# results = [a for a in aggrigation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = path.join('C:/Users', 'ahoward', 'Downloads')\n",
    "dir_2018 = 'Accounts_Monthly_Data-March2018'\n",
    "dir_2019 = 'Accounts_Monthly_Data-March2019'\n",
    "dir_2020 = 'Accounts_Monthly_Data-March2020'\n",
    "dir_2021 = 'Accounts_Monthly_Data-March2021'\n",
    "\n",
    "accounts_2018 = path.join(root, dir_2018)\n",
    "accounts_2019 = path.join(root, dir_2019)\n",
    "accounts_2020 = path.join(root, dir_2020)\n",
    "accounts_2021 = path.join(root, dir_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_2018 = listdir(accounts_2018)\n",
    "files_2019 = listdir(accounts_2019)\n",
    "files_2020 = listdir(accounts_2020)\n",
    "files_2021 = listdir(accounts_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "945782"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [path.join(accounts_2018, f) for f in files_2018]\n",
    "files += [path.join(accounts_2019, f) for f in files_2019]\n",
    "files += [path.join(accounts_2020, f) for f in files_2020]\n",
    "files += [path.join(accounts_2021, f) for f in files_2021]\n",
    "\n",
    "# all_size = 0\n",
    "# for f in tqdm(files):\n",
    "#     all_size += stat(f).st_size\n",
    "# print(f'All files size: {all_size} B')\n",
    "# print(f'All files size: {all_size / (1024**2)} MB')\n",
    "# print(f'All files size: {all_size / (1024**3)} GB')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df18 = pd.DataFrame(data=files_2018, columns = ['Files'])\n",
    "df18['RegNo'] = df18['Files'].str.split('_', expand=True)[2]\n",
    "df18['Date'] = pd.to_datetime(df18['Files'].str.split('_', expand=True)[3].str.split('.', expand=True)[0], format='%Y%m%d')\n",
    "df18['Files'] = dir_2018 + '/' + df18['Files'].astype(str)\n",
    "\n",
    "df19 = pd.DataFrame(data=files_2019, columns = ['Files'])\n",
    "df19['RegNo'] = df19['Files'].str.split('_', expand=True)[2]\n",
    "df19['Date'] = pd.to_datetime(df19['Files'].str.split('_', expand=True)[3].str.split('.', expand=True)[0], format='%Y%m%d')\n",
    "df19['Files'] = dir_2019 + '/' + df19['Files'].astype(str)\n",
    "\n",
    "df20 = pd.DataFrame(data=files_2020, columns = ['Files'])\n",
    "df20['RegNo'] = df20['Files'].str.split('_', expand=True)[2]\n",
    "df20['Date'] = pd.to_datetime(df20['Files'].str.split('_', expand=True)[3].str.split('.', expand=True)[0], format='%Y%m%d')\n",
    "df20['Files'] = dir_2020 + '/' + df20['Files'].astype(str)\n",
    "\n",
    "df21 = pd.DataFrame(data=files_2021, columns = ['Files'])\n",
    "df21['RegNo'] = df21['Files'].str.split('_', expand=True)[2]\n",
    "df21['Date'] = pd.to_datetime(df21['Files'].str.split('_', expand=True)[3].str.split('.', expand=True)[0], format='%Y%m%d')\n",
    "df21['Files'] = dir_2021 + '/' + df21['Files'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18: 195484\n",
      "19: 212415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43012"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'18: {len(df18)}')\n",
    "print(f'19: {len(df19)}')\n",
    "10753 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = (\n",
    "    df18\n",
    "    .merge(df19, 'inner', 'RegNo', suffixes=('_18', '_19'))\n",
    "    .merge(df20, 'inner', 'RegNo', suffixes=('_19', '_20'))\n",
    "    .merge(df21, 'inner', 'RegNo', suffixes=('_20', '_21'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10753, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samp = df_all.sample(100, random_state=100)\n",
    "len(df_samp['Files_18'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac89b9f94674a049f26d59224f7ce8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "years = [18, 19, 20, 21]\n",
    "file_list = []\n",
    "for y in tqdm(years):\n",
    "    file_list += df_samp[f'Files_{y}'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined file size: 32339073 B\n",
      "Combined file size: 30.840943336486816 MB\n"
     ]
    }
   ],
   "source": [
    "total_size = 0\n",
    "for f in file_list:\n",
    "    total_size += stat(path.join(root, f)).st_size\n",
    "\n",
    "print(f'Combined file size: {total_size} B')\n",
    "print(f'Combined file size: {total_size / (1024**2)} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81eaee0190ca4d20bace350870535133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "59\n",
      "89\n",
      "99\n",
      "101\n",
      "159\n",
      "189\n",
      "198\n",
      "199\n",
      "201\n",
      "259\n",
      "289\n",
      "298\n",
      "299\n",
      "301\n",
      "359\n",
      "389\n",
      "398\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "from digiaccounts.digiaccounts_data import get_entity_equity, get_entity_turnover, get_intangible_assets\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "cache = HttpCache('./cache')\n",
    "cache.set_headers({'From': 'ahoward@companieshouse.gov.uk', 'User-Agent': 'py-xbrl/2.1.0'})\n",
    "parser = XbrlParser(cache)\n",
    "\n",
    "no_turnover = 0\n",
    "\n",
    "turnover = []\n",
    "index = 0\n",
    "\n",
    "for f in (pbar := tqdm(file_list)):\n",
    "\n",
    "    account_path = path.join(root, f)\n",
    "    parsed = False\n",
    "    try:\n",
    "        xbrl_instance = parser.parse_instance(account_path)\n",
    "        parsed = True\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    if parsed:\n",
    "        try:\n",
    "            current, previous = get_intangible_assets(xbrl_instance)\n",
    "            d = {'current': current, 'previous': previous}\n",
    "            turnover.append(d)\n",
    "            print(index)\n",
    "        except KeyError:\n",
    "            no_turnover += 1\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'current': 175.0, 'previous': 175.0},\n",
       " {'current': 120000.0, 'previous': 120000.0},\n",
       " {'current': 0.0, 'previous': 0.0},\n",
       " {'current': 30000.0, 'previous': 30000.0},\n",
       " {'current': 0.0, 'previous': 0.0},\n",
       " {'current': 96000.0, 'previous': 96000.0},\n",
       " {'current': 0.0, 'previous': 0.0},\n",
       " {'current': None, 'previous': 0.0},\n",
       " {'current': 20000.0, 'previous': 20000.0},\n",
       " {'current': 0.0, 'previous': 0.0},\n",
       " {'current': 96000.0, 'previous': 96000.0},\n",
       " {'current': 0.0, 'previous': 0.0},\n",
       " {'current': None, 'previous': 0.0},\n",
       " {'current': 10000.0, 'previous': 10000.0},\n",
       " {'current': 0.0, 'previous': 0.0},\n",
       " {'current': 60000.0, 'previous': 60000.0},\n",
       " {'current': 0.0, 'previous': 0.0},\n",
       " {'current': None, 'previous': 0.0},\n",
       " {'current': None, 'previous': None}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users\\ahoward\\Downloads\\Accounts_Monthly_Data-March2021/Prod224_0088_NI044157_20201231.html\n",
      "2020-01-01\n",
      "2020-12-31\n",
      "2019-12-31\n",
      "2019-12-31\n"
     ]
    }
   ],
   "source": [
    "account_path = path.join(root, file_list[399])\n",
    "xbrl_instance = parser.parse_instance(account_path)\n",
    "start, end = get_startend_period(xbrl_instance)\n",
    "print(account_path)\n",
    "print(start)\n",
    "print(end)\n",
    "for f in xbrl_instance.facts:\n",
    "    if f.concept.name == 'IntangibleAssets':\n",
    "        print(f.context.instant_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_intangible_assets(xbrl_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61385b7136774fa88f41388a1e7e1a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "cache = HttpCache('./cache')\n",
    "cache.set_headers({'From': 'ahoward@companieshouse.gov.uk', 'User-Agent': 'py-xbrl/2.1.0'})\n",
    "parser = XbrlParser(cache)\n",
    "\n",
    "reported_dict = {}\n",
    "lookup = None\n",
    "\n",
    "\n",
    "errors = 0\n",
    "no_given_address = 0\n",
    "problem_instances = []\n",
    "problem_addresses = []\n",
    "\n",
    "for f in (pbar := tqdm(file_list)):\n",
    "    pbar.set_description(f'Parse Errors: {errors}')\n",
    "    account_path = path.join(root, f)\n",
    "    \n",
    "    parsed = False\n",
    "    try:\n",
    "        xbrl_instance = parser.parse_instance(account_path)\n",
    "        parsed = True\n",
    "    except:\n",
    "        problem_instances.append(f)\n",
    "        errors += 1\n",
    "    \n",
    "\n",
    "    if parsed:\n",
    "        unique_id = create_unique_id(f)\n",
    "        account_dictionary = get_account_information_dictionary(unique_id, xbrl_instance)\n",
    "        add_account_to_collection(filed_accounts, account_dictionary)\n",
    "\n",
    "\n",
    "with open('problem_files.json', 'w') as f:\n",
    "    json.dump(problem_instances, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = problem_instances[1]\n",
    "# accounts_errors = []\n",
    "# for f in problem_instances:\n",
    "#     #print(f)\n",
    "#     account_path = path.join(root, f)\n",
    "#     try:\n",
    "#         xbrl_instance = parser.parse_instance(account_path)\n",
    "#     except KeyError as e:\n",
    "#         accounts_errors.append([str(e), account_path])\n",
    "#     except Exception as e:\n",
    "#         accounts_errors.append([str(e), account_path])\n",
    "# with open('account_errors.json', 'w') as o:\n",
    "#     json.dump(accounts_errors, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2018/Prod224_0052_07668935_20170630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2018/Prod224_0052_05697829_20180228.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2018/Prod224_0052_03801700_20170630.html'],\n",
       " [\"'charmap' codec can't decode byte 0x9d in position 28349: character maps to <undefined>\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2018/Prod224_0052_04430950_20170630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2018/Prod224_0052_SC344948_20170630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2018/Prod224_0052_08584936_20170630.html'],\n",
       " [\"'charmap' codec can't decode byte 0x9d in position 32810: character maps to <undefined>\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2018/Prod224_0052_07308320_20170630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2018/Prod224_0052_08120998_20170630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2018/Prod224_0052_03576003_20170630.html'],\n",
       " [\"'charmap' codec can't decode byte 0x9d in position 22403: character maps to <undefined>\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2018/Prod224_0052_09104821_20170630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2019/Prod224_0064_07668935_20180630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2019/Prod224_0064_08349846_20181231.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2019/Prod224_0064_05697829_20190228.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2019/Prod224_0064_03801700_20180630.html'],\n",
       " [\"'charmap' codec can't decode byte 0x9d in position 24811: character maps to <undefined>\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2019/Prod224_0064_04430950_20180630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2019/Prod224_0064_SC344948_20180630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2019/Prod224_0064_08584936_20180630.html'],\n",
       " [\"'charmap' codec can't decode byte 0x9d in position 27648: character maps to <undefined>\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2019/Prod224_0064_07308320_20180630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2019/Prod224_0064_08120998_20180630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2019/Prod224_0064_03576003_20180630.html'],\n",
       " [\"'charmap' codec can't decode byte 0x9d in position 17678: character maps to <undefined>\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2019/Prod224_0064_09104821_20180630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2020/Prod224_0076_07668935_20190630.html'],\n",
       " [\"'charmap' codec can't decode byte 0x9d in position 19242: character maps to <undefined>\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2020/Prod224_0076_06921736_20190630.html'],\n",
       " [\"'charmap' codec can't decode byte 0x9d in position 262752: character maps to <undefined>\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2020/Prod224_0076_05697829_20200228.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2020/Prod224_0076_03801700_20190630.html'],\n",
       " [\"'charmap' codec can't decode byte 0x9d in position 24986: character maps to <undefined>\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2020/Prod224_0076_04430950_20190630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2020/Prod224_0076_SC344948_20190630.html'],\n",
       " ['The taxonomy with namespace http://www.govtalk.gov.uk/uk/fr/tax/dpl-core/2013-10-01 could not be found. Please check if it is imported in the schema file',\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2020/Prod224_0076_05453907_20190630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2020/Prod224_0076_08584936_20190630.html'],\n",
       " [\"'charmap' codec can't decode byte 0x9d in position 27931: character maps to <undefined>\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2020/Prod224_0076_07308320_20190630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2020/Prod224_0076_08120998_20190630.html'],\n",
       " [\"'dpl-countries'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2020/Prod224_0076_03576003_20190630.html'],\n",
       " [\"'charmap' codec can't decode byte 0x9d in position 17832: character maps to <undefined>\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2020/Prod224_0076_09104821_20190630.html'],\n",
       " [\"'dpl-frs'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2021/Prod224_0088_07668935_20200630.html'],\n",
       " [\"'dpl-frs'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2021/Prod224_0088_08349846_20201231.html'],\n",
       " [\"'dpl-frs'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2021/Prod224_0088_05697829_20210228.html'],\n",
       " [\"'dpl-frs'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2021/Prod224_0088_03801700_20200630.html'],\n",
       " [\"'charmap' codec can't decode byte 0x9d in position 25587: character maps to <undefined>\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2021/Prod224_0088_04430950_20200630.html'],\n",
       " [\"'dpl-frs'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2021/Prod224_0088_SC344948_20200630.html'],\n",
       " [\"'dpl-frs'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2021/Prod224_0088_08584936_20200630.html'],\n",
       " [\"'charmap' codec can't decode byte 0x9d in position 27950: character maps to <undefined>\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2021/Prod224_0088_07308320_20200630.html'],\n",
       " [\"'dpl-frs'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2021/Prod224_0088_08120998_20200630.html'],\n",
       " [\"'dpl-frs'\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2021/Prod224_0088_03576003_20200630.html'],\n",
       " [\"'charmap' codec can't decode byte 0x9d in position 19599: character maps to <undefined>\",\n",
       "  'C:/Users\\\\ahoward\\\\Downloads\\\\Accounts_Monthly_Data-March2021/Prod224_0088_09104821_20200630.html']]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accounts_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "strptime() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ahoward\\Projects\\DigitalAccounts\\multi_account_sandbox.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ahoward/Projects/DigitalAccounts/multi_account_sandbox.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m datetime\u001b[39m.\u001b[39;49mstrptime(\u001b[39m'\u001b[39;49m\u001b[39m30 June 2020\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: strptime() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "datetime.strptime('30 June 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-06-30'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dateutil.parser\n",
    "\n",
    "dateutil.parser.parse('30 June 2020').date().isoformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = None\n",
    "end = None\n",
    "\n",
    "all(period is None for period in [start, end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = ['foo', 'bar', 'foobar']\n",
    "\n",
    "len([f for f in array if 'foo' in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import dateutil\n",
    "period = '2020-07-01/2021-06-30'\n",
    "start = '2020-07-01'\n",
    "end = '2021-06-30'\n",
    "\n",
    "period_start, period_end = period.split('/')\n",
    "\n",
    "print (\n",
    "    dateutil.parser.parse(period_start) <= dateutil.parser.parse(start)\n",
    ")\n",
    "print (\n",
    "    dateutil.parser.parse(period_end) >= dateutil.parser.parse(end)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('DefaultDataScience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8270e447217dfb8aa50efce57c8b0fee6196620bc8c4c1bb30fc34f6cadd18e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
